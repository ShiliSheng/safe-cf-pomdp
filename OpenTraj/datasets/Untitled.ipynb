{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db61033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ETH/'\n",
    "path += \"/seq_eth/obsmat.txt\"\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08214102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique agent 360\n"
     ]
    }
   ],
   "source": [
    "csv_columns = [\"frame_id\", \"id\", \"x\", \"z\", \"y\", \"vel_x\", \"vel_z\", \"vel_y\"]\n",
    "# read from csv => fill traj table\n",
    "raw_dataset = pd.read_csv(path, sep=r\"\\s+\", header=None, names=csv_columns)\n",
    "raw_dataset[\"timestamp\"]= raw_dataset.frame_id\n",
    "start_frame = raw_dataset.frame_id.min()\n",
    "d_frame = np.diff(pd.unique(raw_dataset[\"frame_id\"]))\n",
    "fps = d_frame[0] * 2.5  # 2.5 is the common annotation\n",
    "for i in raw_dataset.index:\n",
    "    raw_dataset.loc[i, \"timestamp\"] = (raw_dataset.loc[i, \"frame_id\"] - start_frame) / fps\n",
    "raw_dataset = raw_dataset.loc[:, [\"timestamp\", \"id\", \"x\", \"y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70f63f",
   "metadata": {},
   "source": [
    "split data into train_id, testid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d343bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id, test_id = train_test_split(raw_dataset.id.unique(), test_size= 1 / 10, random_state=42)\n",
    "train_id, test_id = set(train_id), set(test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68b3e9",
   "metadata": {},
   "source": [
    "create dataset using, history_length, prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a86be7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lenth = 10\n",
    "history_length = 5\n",
    "prediction_length = 2\n",
    "total_sequence_length = history_length + prediction_length\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "for pid, group in raw_dataset.groupby(\"id\"):\n",
    "    timestamps = group[\"timestamp\"].values\n",
    "    x_values = group[\"x\"].values\n",
    "    y_values = group[\"y\"].values\n",
    "\n",
    "    for i in range(len(group) - total_sequence_length + 1):\n",
    "        # Extract the sequence and target\n",
    "        sequence = np.column_stack((x_values[i:i+history_length], y_values[i:i+history_length]))\n",
    "        target = np.column_stack((x_values[i+history_length:i+total_sequence_length], y_values[i+history_length:i+total_sequence_length]))\n",
    "        if pid in train_id:\n",
    "            train_dataset.append((torch.tensor(sequence, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)))\n",
    "        else:\n",
    "            test_dataset.append((torch.tensor(sequence, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)))\n",
    "\n",
    "# Convert to PyTorch DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# for batch_input, batch_target in train_loader:\n",
    "#     # Check the shape of the input sequences in the first batch\n",
    "#     print(\"Shape of input sequences:\", batch_input.shape)\n",
    "\n",
    "#     # Check the shape of the target sequences in the first batch\n",
    "#     print(\"Shape of target sequences:\", batch_target.shape)\n",
    "\n",
    "#     # Assuming each sequence has two features (x, y)\n",
    "#     num_features = batch_input.size(-1)\n",
    "#     print(\"Number of features:\", num_features)\n",
    "\n",
    "#     # Assuming sequences have variable lengths\n",
    "#     sequence_lengths = (batch_input != 0).sum(dim=1)\n",
    "#     print(\"Sequence lengths:\", sequence_lengths)\n",
    "\n",
    "#     # Break after checking the first batch\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "696c5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6.3642\n",
      "Epoch [2/10], Loss: 1.6703\n",
      "Epoch [3/10], Loss: 0.9372\n",
      "Epoch [4/10], Loss: 0.2694\n",
      "Epoch [5/10], Loss: 0.1391\n",
      "Epoch [6/10], Loss: 0.1594\n",
      "Epoch [7/10], Loss: 0.0637\n",
      "Epoch [8/10], Loss: 0.0936\n",
      "Epoch [9/10], Loss: 0.0654\n",
      "Epoch [10/10], Loss: 0.0366\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a simple LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Assuming you want to predict from the last timestep\n",
    "        return output\n",
    "# Assuming 'input_size', 'hidden_size', and 'output_size' are appropriate values\n",
    "input_size = 2  # Assuming 2 features (x, y) per timestep\n",
    "hidden_size = 64\n",
    "output_size = 2  # Assuming 2 features in the output\n",
    "# Create an instance of the model\n",
    "model = LSTMModel(input_size, hidden_size, output_size * prediction_length)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "# Assuming 'train_loader' is your DataLoader\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_input, batch_target in train_loader:\n",
    "        # Forward pass\n",
    "        batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "\n",
    "        output = model(batch_input)\n",
    "        output = output.view(-1, prediction_length, output_size)\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, batch_target)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Print the loss after each epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "# Training complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4623f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss on Test Set: 0.0010 650\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'test_loader' is your DataLoader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_loss = 0.0\n",
    "num_samples = 0\n",
    "# Disable gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    for batch_input, batch_target in test_loader:\n",
    "        batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "        # Forward pass\n",
    "        output = model(batch_input)\n",
    "        # Reshape the output to match the target shape\n",
    "        output = output.view(-1, prediction_length, output_size)\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, batch_target)\n",
    "        total_loss += loss.item()\n",
    "        num_samples += batch_input.size(0)\n",
    "# Calculate the average loss\n",
    "average_loss = total_loss / num_samples\n",
    "print(f'Average Loss on Test Set: {average_loss:.4f}', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e155b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[13]\n",
    "test_a = [[7.4008, 5.3609],\n",
    "         [6.9278, 5.4221],\n",
    "         [6.6198, 5.3929],\n",
    "         [6.1320, 5.3706],\n",
    "         [5.5926, 5.3497]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "771c2619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.230974 , 5.1471486],\n",
       "       [4.8149676, 5.107736 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_a = test_dataset[13][0]\n",
    "# Assuming 'test_a' is your single sequence with history length (x, y)\n",
    "# Assuming 'model' is your trained LSTM model\n",
    "# Preprocess the sequence (assuming it's a NumPy array)\n",
    "test_a_tensor = torch.tensor(test_a, dtype=torch.float32).clone().detach().unsqueeze(0)  # Add batch dimension\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "# Make the prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_a_tensor = test_a_tensor.to(device)\n",
    "\n",
    "    model_output = model(test_a_tensor)\n",
    "# Reshape the output to match the target shape\n",
    "model_output = model_output.view(-1, prediction_length, output_size)\n",
    "# Extract the predicted values for the next steps\n",
    "\n",
    "predicted_values = model_output[0, -prediction_length:, :].numpy()\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bf03cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "865a72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/wkgzj0_d59xghrtzj8qr5prh0000gn/T/ipykernel_14116/4151446205.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_a_tensor = torch.tensor(test_a, dtype=torch.float32).clone().detach().unsqueeze(0)  # Add batch dimension\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.2309985, 5.1471295],\n",
       "       [4.8149967, 5.107718 ]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'ModelClass' is the class of your model (the same class used for training)\n",
    "input_size = 2  # Assuming 2 features (x, y) per timestep\n",
    "hidden_size = 64\n",
    "output_size = 2  # Assuming 2 features in the output\n",
    "# Create an instance of the model\n",
    "model = LSTMModel(input_size, hidden_size, output_size * prediction_length)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('./model_weights.pth', map_location=device))\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "test_a = test_dataset[13][0]\n",
    "# Assuming 'test_a' is your single sequence with history length (x, y)\n",
    "# Assuming 'model' is your trained LSTM model\n",
    "# Preprocess the sequence (assuming it's a NumPy array)\n",
    "test_a_tensor = torch.tensor(test_a, dtype=torch.float32).clone().detach().unsqueeze(0)  # Add batch dimension\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "# Make the prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_a_tensor = test_a_tensor.to(device)\n",
    "\n",
    "    model_output = model(test_a_tensor)\n",
    "# Reshape the output to match the target shape\n",
    "model_output = model_output.view(-1, prediction_length, output_size)\n",
    "# Extract the predicted values for the next steps\n",
    "\n",
    "predicted_values = model_output[0, -prediction_length:, :].cpu().numpy()  # Move back to CPU for further processing if needed\n",
    "\n",
    "predicted_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
